{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb9b7af-672f-42ce-8d6d-bc185f9e7461",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>SBAE - Notebook Series - Part 3, version 0.2,  September 2022. Andreas Vollrath, UN-Food and Agricultural Organization, Rome</i>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1552bf-09e5-4cae-82fe-8166038f2cd1",
   "metadata": {},
   "source": [
    "![title](images/header.png)\n",
    "\n",
    "# III A - SBAE - spatially balanced subsampling\n",
    "### Extract a subset of samples from K-Means clusters \n",
    "-------\n",
    "\n",
    "This notebook takes you through the process of creating a sub-sample of the time-series and change data retrieved in II. The objective is to obtain a statisitically balanced subsample that can be used for training data collection, and ideally includes a higher precentage of rare classes such as de-forestation, degradation and gain when compared to a pure random subsampling approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f556f1-c95d-4802-80d2-86acf18c8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df1d844-c25a-413c-9840-3ce5280b57b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data management\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sbae internal functionality  \n",
    "import helpers as h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e95ec9-e480-4188-8dc3-fc6d884e553e",
   "metadata": {},
   "source": [
    "### 1 Load geopackage results file\n",
    "\n",
    "The first step is to load the results file from Notebook II of the SBAE notebook series. This file should contain the outputs from various time-series algorithms and may additionally hold extracts from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b905bed-c71f-4ff2-859f-96733b03ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('results_geopackage_file.gpkg')\n",
    "\n",
    "print('Available Columns')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69575941-b750-4538-a618-0deb1f0415ae",
   "metadata": {},
   "source": [
    "### 2 Select relavant columns for creating the clusters\n",
    "\n",
    "Not all columns in the loaded data should go into the clustering process, e.g. the point_id does not tell us anything about the statistical distribution with regard to change. In the cell below is a pre-selection of columns that potentially contain information on change and therefore shall be helpful in creating meaningful clusters for later subsampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a8cba6-7d64-4395-918d-89187ffae3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columsn thata re used by Kmeans\n",
    "cols_to_cluster = [\n",
    "    'mon_images',\n",
    "    'elevation',\n",
    "    'dw_class_mode', 'dw_tree_prob__max',\n",
    "    'dw_tree_prob__min', 'dw_tree_prob__stdDev', 'dw_tree_prob_mean',\n",
    "    'bfast_magnitude', 'bfast_means', \n",
    "    #'lang_tree_height', \n",
    "    'potapov_tree_height',\n",
    "    'ccdc_magnitude',\n",
    "    'ltr_magnitude', 'ltr_dur', 'ltr_rate', \n",
    "    'cusum_confidence', 'cusum_magnitude', \n",
    "    'ts_mean', 'ts_sd', 'ts_min', 'ts_max', \n",
    "    'bs_slope_mean', 'bs_slope_sd', 'bs_slope_min', 'bs_slope_max'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8711d8bc-8a43-44bf-a332-5aae37e11770",
   "metadata": {},
   "source": [
    "### 3 Check for NaNs\n",
    "\n",
    "The clustering process does not accept NaNs in any of the fields. There are 2 strategies:\n",
    "\n",
    "1. Remove all rows that contain any NaNs\n",
    "2. Replace all NaNs with a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22156072-817e-46c2-a9f0-1f147a63308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Length of original dataframe: ' + str(len(df)))\n",
    "df_1 = df.copy()\n",
    "print(' Length of nan-removed dataframe: ' + str(len(df_1[cols_to_cluster].dropna())))\n",
    "\n",
    "for col in cols_to_cluster:\n",
    "    print(f' Column {col} contains {len(df_1[df_1[col].isna()])} NaNs')\n",
    "    # print(f' Column {col} contains {len(df_1[df_1[col].isin([np.inf, -np.inf])])} Infinites')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d61e91-08da-41e5-948b-22a761bd2a9e",
   "metadata": {},
   "source": [
    "# 2 K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b487af-c16d-4769-a2f8-2f4a88343978",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_cluster=50\n",
    "\n",
    "# run kmeans\n",
    "kmeans = KMeans(n_clusters=nr_of_cluster, random_state=42).fit(df[cols_to_cluster])\n",
    "\n",
    "#------------------------------------------------\n",
    "# Standardize the data\n",
    "#X_std = StandardScaler().fit_transform(df[cols_to_cluster])\n",
    "# run kmeans with standardized data\n",
    "#kmeans = KMeans(n_clusters=nr_of_cluster, random_state=42).fit(X_std)\n",
    "#------------------------------------------------\n",
    "\n",
    "# add the cluster column\n",
    "df['Kmeans'] = kmeans.predict(df[cols_to_cluster])\n",
    "\n",
    "# print number of points per clusters\n",
    "clusters, counts = np.unique(df.Kmeans, return_counts=True)\n",
    "print(clusters)\n",
    "print(counts)\n",
    "\n",
    "# plot data\n",
    "pd.DataFrame({'counts': counts}).plot(kind='bar', title='Nr. of Points per cluster', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25d0af6-1297-4ea4-ae5a-5761e30da388",
   "metadata": {},
   "source": [
    "# 3 Plots\n",
    "\n",
    "## 3.1 Plot Statistics of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf67ad-6acb-406f-b02d-d899b7c96acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_plot = cols_to_cluster\n",
    "\n",
    "# in case you want to have that different\n",
    "#cols_to_plot = [\n",
    "#    'mon_images',\n",
    "#    'cusum_confidence', 'cusum_magnitude', \n",
    "#    'ts_mean', 'ts_sd', 'ts_min', 'ts_max', \n",
    "#    'bs_slope_mean', 'bs_slope_sd', 'bs_slope_min', 'bs_slope_max'\n",
    "#]\n",
    "\n",
    "\n",
    "fig, axs = h.plot_stats_per_class(df, 'Kmeans', cols_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb29ae-3771-4218-aaf0-1b11b948eb27",
   "metadata": {},
   "source": [
    "## 3.2 Highlight specific clsuter on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ee1ad-3291-4d76-ae79-ee818d9a978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_highlight = 11\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "df.plot(ax=ax, column='Kmeans', legend=True, markersize=.1)\n",
    "df[df['Kmeans']==cluster_to_highlight].plot(ax=ax, markersize=5, facecolor='red')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad080be-f724-4e97-a7b3-5b29076da68d",
   "metadata": {},
   "source": [
    "# 4 Select subset of samples for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb77e3-f39e-4aaa-b5e6-754950df565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_samples_per_cluster = 25\n",
    "subset_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "for cluster in df.Kmeans.unique():\n",
    "    \n",
    "    if len(df[df.Kmeans == cluster]) < nr_of_samples_per_cluster:\n",
    "        \n",
    "        subset_df = pd.concat([\n",
    "            subset_df,\n",
    "            df[df.Kmeans == cluster].sample(len(df[df.Kmeans == cluster]))\n",
    "        ])\n",
    "    else:\n",
    "        \n",
    "        subset_df = pd.concat([\n",
    "            subset_df,\n",
    "            df[df.Kmeans == cluster].sample(nr_of_samples_per_cluster)\n",
    "        ])\n",
    "    \n",
    "print(f'{len(subset_df)} samples have been selected in total')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "subset_df = gpd.GeoDataFrame(subset_df, geometry='geometry')\n",
    "subset_df.plot(column='Kmeans', ax=ax, legend=True, markersize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864effe0-d3c0-4bdb-8256-b43571dc2d43",
   "metadata": {},
   "source": [
    "# 5 Convert to CEO file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b292d3-f0d6-4105-871d-c8ad36fb9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_csv_file = 'path/to/subset_results.csv'\n",
    "\n",
    "subset_df['LON'] = gpd.GeoDataFrame(subset_df).geometry.x\n",
    "subset_df['LAT'] = gpd.GeoDataFrame(subset_df).geometry.y\n",
    "subset_df['PLOTID'] = gpd.GeoDataFrame(subset_df).point_id\n",
    "\n",
    "cols = subset_df.columns.tolist()\n",
    "cols = [e for e in cols if e not in ('LON', 'LAT', 'PLOTID')]\n",
    "new_cols = ['LON', 'LAT', 'PLOTID'] + cols\n",
    "subset_df = subset_df[new_cols]\n",
    "subset_df.to_csv(out_csv_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
