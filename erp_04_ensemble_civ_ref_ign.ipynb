{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e3013a-d2b2-4477-bb18-e6c2de6db506",
   "metadata": {},
   "source": [
    "![titre](images/header.png)\n",
    "\n",
    "# IV A - SBAE - Classification supervisée\n",
    "### Utiliser des données de référence pour entrainer une classification\n",
    "-------\n",
    "\n",
    "Ce bloc-notes vous guide tout au long du processus de création d'un sous-échantillon de la série chronologique et des données de modification récupérées dans III et interprétées visuellement. \n",
    "L'objectif est d'obtenir une variable continue qui décrive la population (par ex. probabilité de changement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1ceac7-b6d0-48c4-96b5-f08fdb21e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix, classification_report\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4edb8a3-d1ee-4cb4-943a-a819fdc66862",
   "metadata": {},
   "source": [
    "### 1 Charger et préparer les données CEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc2c7b-1443-46cd-b8d9-be85754946ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "ceo = pd.read_csv('/home/sepal-user/sbae_point_analysis_CIV/erp_1km/ign_ERP_CIV_692pts_20221026.csv', delimiter=',')\n",
    "print(ceo.columns)\n",
    "ceo.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2305da-1174-4265-b3e0-5577f7103b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset columns\n",
    "ceo = ceoIC[['PLOTID', 'LON', 'LAT', 'CHG_00_10', 'CHG_10_15']]\n",
    "\n",
    "# add CNC column for classification\n",
    "ceo['cnc_0010'] = ceo['CHG_00_10'].apply(lambda x: 1 if x == 'Deforestation' else 0)\n",
    "ceo['cnc_1015'] = ceo['CHG_10_15'].apply(lambda x: 1 if x == 'Deforestation' else 0)\n",
    "ceo['cnc']      = ceo['cnc_0010'] + ceo['cnc_1015']\n",
    "\n",
    "ceo.head(5)\n",
    "np.unique(ceo['cnc'], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b5964-e1b9-4b15-83c8-d3e350128ef9",
   "metadata": {},
   "source": [
    "### 2 Charger et préparer les données TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c01fd-a56a-4df6-8f04-eb37f7657c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "ts = pd.read_pickle('/home/sepal-user/sbae_point_analysis_CIV/erp_1km/erp_bdd_ts_aux_1km.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3f6026-e0dd-40a3-ac3f-563cf808e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[['dates', 'ts', 'images']].head(5)\n",
    "len(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d32190-2ca7-4f26-8502-5e34542d0f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn nan to 0\n",
    "ts['gfc_lossyear'] = np.nan_to_num(ts['gfc_lossyear'])\n",
    "# create a binary loss\n",
    "ts['gfc_loss_binary'] = ts['gfc_lossyear'].apply(lambda x: 0 if x == 0 or x > 15 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff0fb7-e11e-4701-b885-d182d58a9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a binary deforestation\n",
    "ts['tmf_def_binary'] = ts['tmf_defyear'].apply(lambda x: 1 if x > 1999 and x <= 2015 else 0)\n",
    "\n",
    "# create a binary degradation\n",
    "ts['tmf_deg_binary'] = ts['tmf_degyear'].apply(lambda x: 1 if x > 1999 and x <= 2015 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedc4c2b-a4a6-48d1-900e-f486d310370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts['ltr_magnitude'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058deb2e-2fd4-4ed1-a4f1-f583798d47d8",
   "metadata": {},
   "source": [
    "### 2.1 Sélectionner les colonnes pour la classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1503bf-eda5-4eae-bfa1-59786a64cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_classify = [\n",
    "    'images', 'mon_images',\n",
    "    'gfc_tc00', \n",
    "    'gfc_loss_binary',\n",
    "    'tmf_2000', \n",
    "    'tmf_def_binary', 'tmf_deg_binary',\n",
    "    'bfast_magnitude',\n",
    "    'ccdc_magnitude', \n",
    "    'ltr_magnitude', 'ltr_dur', 'ltr_rate',\n",
    "    'cusum_confidence', 'cusum_magnitude', \n",
    "    'ts_mean', 'ts_sd', # we add this anyway in the next cell\n",
    "    'ts_min', 'ts_max',\n",
    "    'bs_slope_mean', 'bs_slope_sd', 'bs_slope_max', 'bs_slope_min'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a71c9a2-b7e5-4347-b972-d587e3674b8c",
   "metadata": {},
   "source": [
    "### 2.2 Extraire des statistiques de séries chronologiques pour chaque bande et les ajouter aux colonnes de données prédictives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5780867d-0029-4b1c-9b6a-27ecf0d0ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = list(ts['ts'][1].keys())\n",
    "print(' Bands available in dataset time-series: ')\n",
    "print(bands) \n",
    "for band in bands:\n",
    "    \n",
    "    # add mean and SD value of time-series for each band\n",
    "    ts[band + '_mean'] = ts['ts'].apply(lambda x: np.nanmean(np.array(x[band])))\n",
    "    ts[band + '_sd'] = ts['ts'].apply(lambda x: np.nanstd(np.array(x[band])))\n",
    "    \n",
    "    # append to classification bands\n",
    "    cols_to_classify.append(band + '_mean')\n",
    "    cols_to_classify.append(band + '_sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461bc62b-b283-49c6-8f6b-19e30326a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5199ae-979e-4c72-8837-2d625b872c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Number of predictive features: ' + str(len(cols_to_classify)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37185585-2d0b-4499-92f4-7b8da6e6a919",
   "metadata": {},
   "source": [
    "### 2.3 Ajouter une colonne Kmeans (parce que nous le pouvons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe2dc6-1ba9-4b03-bbb1-ad09488a9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_cluster=50\n",
    "\n",
    "# run kmeans\n",
    "kmeans_model = KMeans(n_clusters=nr_of_cluster, random_state=42).fit(ts[cols_to_classify])\n",
    "ts['kmeans'] = kmeans_model.predict(ts[cols_to_classify])\n",
    "\n",
    "cols_to_classify.append('kmeans')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f2d440-bc51-41ed-a86a-8a3262f60e54",
   "metadata": {},
   "source": [
    "### 3 Fusionner les données CEO et de TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b47380-e380-4c29-951c-0300b379d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = pd.merge(ceo, ts[cols_to_classify + ['PLOTID']], how='inner', left_on='PLOTID', right_on='PLOTID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a69f67-b3cb-4b41-ad51-26ed7c9b3ecf",
   "metadata": {},
   "source": [
    "### 4 Classification - Création d'un modèle d'ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4035b2-601b-4cce-9d90-13b0f8f916f6",
   "metadata": {},
   "source": [
    "### 4.1 Partage entre Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9614822-d4f4-4fbb-8db4-2e583e3e8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_class[cols_to_classify + ['PLOTID']], df_class['cnc'], test_size=0.2, random_state=42, stratify=df_class['cnc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c5a20-0e74-4fb4-8a6d-520e13ca80be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5db5b-bc9c-4e9a-af27-ec9f39094324",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test\n",
    "len(X_test)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7654c198-ba6b-44de-81f5-bba3dbda3f56",
   "metadata": {},
   "source": [
    "### 4.2 Classification RF avec optimisation automatisée du modèle pour éviter les faux positifs dans la classe stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58296a63-a10a-4818-aeb9-535664ef8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1, oob_score=True)\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': [3, 5, 10], \n",
    "    'n_estimators' : [125, 250, 500],\n",
    "    #'max_depth': [3, 5, 15, 25],\n",
    "    'max_features': [5, 10, 20]\n",
    "}\n",
    "\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "\n",
    "def grid_search_wrapper(refit_score='recall_score'):\n",
    "    \"\"\"\n",
    "    fits a GridSearchCV classifier using refit_score for optimization\n",
    "    prints classifier performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    grid_search = GridSearchCV(clf, param_grid, scoring=scorers, refit=refit_score, cv=skf, return_train_score=True, n_jobs=-1)\n",
    "    grid_search.fit(X_train[cols_to_classify], y_train)\n",
    "\n",
    "    # make the predictions\n",
    "    y_pred = grid_search.predict(X_test[cols_to_classify])\n",
    "\n",
    "    print('Best params for {}'.format(refit_score))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # confusion matrix on the test data.\n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format(refit_score))\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "    return grid_search\n",
    "\n",
    "grid_search_clf = grid_search_wrapper(refit_score='precision_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97890049-1e4a-4b55-8dc3-c9130b0642f7",
   "metadata": {},
   "source": [
    "### 4.3 Précision du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1132a-5a53-471d-9eee-2e5165ed0854",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['class'] = grid_search_clf.predict(X_train[cols_to_classify])\n",
    "X_test['class'] = grid_search_clf.predict(X_test[cols_to_classify])\n",
    "\n",
    "print('-----------------------------')\n",
    "print(' Stats on train:')\n",
    "print('-----------------------------')\n",
    "print('Accuracy on train: ' + str(accuracy_score(y_train, X_train['class'])))\n",
    "display(confusion_matrix(y_train, X_train['class']))\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "print('-----------------------------')\n",
    "print(' Stats on test:')\n",
    "print('-----------------------------')\n",
    "#print('Out of Bag Error RF: ' + str(grid_search_clf.oob_score_))\n",
    "print('Accuracy on test: ' + str(accuracy_score(y_test, X_test['class'], )))\n",
    "cm = confusion_matrix(y_test, X_test['class'])\n",
    "display(cm)\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "print('-----------------------------')\n",
    "print(' Per class stats on test:')\n",
    "print('-----------------------------')\n",
    "print(classification_report(y_test, X_test['class'], target_names=['stable', 'change'], digits=4))\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=['stable', 'change'], columns=['stable', 'change'])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9cb0d3-6673-4b11-bf58-33081fc4f321",
   "metadata": {},
   "source": [
    "### 4.4 Importance des composantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f4d10-21af-410f-8388-d8614fdceb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = grid_search_clf.best_estimator_\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "feature_names = [f\"{i}\" for i in X_train[cols_to_classify].columns]\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using RF\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61305af-3b68-4882-95c0-51ff58386b5d",
   "metadata": {},
   "source": [
    "### 4.4 Détermination du seuil pour ne pas avoir de changement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66128ffc-b770-460f-8ce0-1e79e9dd6898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class[['prob_stable', 'prob_change']] = grid_search_clf.predict_proba(df_class[cols_to_classify][cols_to_classify])\n",
    "\n",
    "print('Maximum probability of stable for change points')\n",
    "#thshld = df_class['prob_stable'][df_class['cnc'] == 1].max()\n",
    "thshld = np.percentile(df_class['prob_stable'][df_class['cnc'] == 1], 100)\n",
    "print(thshld)\n",
    "\n",
    "print('Reasonable probability of stable for change points')\n",
    "#thshld = df_class['prob_stable'][df_class['cnc'] == 1].max()\n",
    "thshld = np.percentile(df_class['prob_stable'][df_class['cnc'] == 1], 90)\n",
    "print(thshld)\n",
    "\n",
    "print('Number of points above thshld (considered stable)')\n",
    "abv_thshld = df_class[df_class['prob_stable'] > thshld]\n",
    "print(str(len(abv_thshld)) + ' out of ' + str(len(df_class)))\n",
    "\n",
    "print('Number of actual change points left in stable')\n",
    "print(len(abv_thshld[abv_thshld['cnc'] == 1]))\n",
    "\n",
    "print(' Point Ids of interpreted change with a high probability of being stable')\n",
    "display(df_class[(df_class['cnc'] == 1) & (df_class['prob_stable'] > thshld)].sort_values('prob_stable', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d857f150-fa6a-4f9f-8cc0-6e7ac14766e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.columns)\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f8bf6b-d226-4898-ba02-a1db0ee56d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[['prob_stable', 'prob_change']] = grid_search_clf.predict_proba(X_test[cols_to_classify])\n",
    "X_test['cnc'] = y_test\n",
    "X_test.to_csv('/home/sepal-user/sbae_point_analysis_CIV/erp_1km/validation_ign_ERP_CIV_IC_113pts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ed21b-d91b-4464-bfdd-2df718069b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class['prob_stable'].hist()\n",
    "len(df_class)\n",
    "\n",
    "X_test['prob_stable'].hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e955a914-f280-4e48-acd5-45157c287e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_ids = df_class[(df_class['cnc'] == 1) & (df_class['prob_stable'] > thshld)]['PLOTID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf7714-af01-4fbc-948f-ab9442cb11a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287bfe0b-05ad-42bf-93c4-5098dca69a83",
   "metadata": {},
   "source": [
    "### 5 Appliquer le modèle d'ensemble à TOUS les points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58bde0-d5df-456e-8782-d9d7e152b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts['cnc_class'] = grid_search_clf.predict(ts[cols_to_classify])\n",
    "ts[['prob_stable', 'prob_change']] = grid_search_clf.predict_proba(ts[cols_to_classify])\n",
    "\n",
    "print(' Number of points to visually recheck based on classification result (0.5 probability)')\n",
    "print(len(ts[ts['cnc_class'] == 1]))\n",
    "\n",
    "\n",
    "print(' Number of points to visually recheck based on adjusted probability')\n",
    "print(len(ts[ts['prob_stable'] < thshld]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad21af0-c506-4269-b482-133447f3d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts['prob_stable'].hist(bins=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac9528-6803-4e3c-8b85-1b617dc5ae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3197036-d954-41fa-a0e7-92313096fe7d",
   "metadata": {},
   "source": [
    "#### Exporter les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c883d5a-e304-4bac-a3c6-681c1b58a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_csv_file = '/home/sepal-user/sbae_point_analysis_CIV/erp_1km/bdd_erp_2000_2015_supervised_IC_ign.csv'\n",
    "#tout = ts[['PLOTID','LON', 'LAT','kmeans','cnc_class', 'prob_stable', 'prob_change']]\n",
    "tout = ts\n",
    "tout.to_csv(out_csv_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068c9151-b989-4fb1-898d-19e9f1057aea",
   "metadata": {},
   "source": [
    "### 6 Sélectionnez les points de changement les plus probables en fonction de la probabilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c695a23-0cfe-43ae-a3a3-282300b78343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of points you can afford to analyse\n",
    "nr_of_points = 3300\n",
    "\n",
    "# select\n",
    "selection = ts[['PLOTID', 'prob_change']].sort_values('prob_change', ascending=False).head(nr_of_points)\n",
    "display(selection)\n",
    "print('Minimum change probability included in selection: ' + str(selection['prob_change'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35635d-121d-4d1c-80d9-7e8c1784a438",
   "metadata": {},
   "source": [
    "### 7 Sélectionnez la plupart des points de zone grise selon le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe223e-b874-4ab7-883d-a254d7be6bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Number of points to visually recheck based on margin of classifier') \n",
    "ts[['PLOTID', 'prob_change']][(ts['prob_change'] > 0.5) & (ts['prob_change'] < 0.55)].sort_values('prob_change', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
